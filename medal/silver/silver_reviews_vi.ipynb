{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j-0i5xH-EcI",
        "outputId": "68012b4a-8dd5-4085-aeac-769549a44a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from transformers import pipeline\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "from langdetect import detect, DetectorFactory\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set seed for reproducibility\n",
        "DetectorFactory.seed = 0\n",
        "\n",
        "# Load the JSON data\n",
        "with open('bus_reviews.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "df = df[['Bus Name', 'Comment']].rename(columns={'Bus Name': 'bus_name', 'Comment': 'comment'})\n",
        "\n",
        "# Function to detect language\n",
        "def detect_language(comment):\n",
        "    try:\n",
        "        return detect(comment)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Split data into English and Vietnamese comments\n",
        "df_vi = df[df['comment'].apply(lambda x: detect_language(x) == 'vi')].reset_index(drop=True)\n",
        "df_en = df[df['comment'].apply(lambda x: detect_language(x) == 'en')].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "5SmRMfZ7IdC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Giả sử 'bus_names' và 'sentences' là danh sách các tên nhà xe và bình luận\n",
        "bus_names = df_en['bus_name']\n",
        "sentences = df_en['comment']\n",
        "\n",
        "# Load tokenizer và model\n",
        "model_path = '5CD-AI/Vietnamese-Sentiment-visobert'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Di chuyển model vào GPU nếu có\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Định nghĩa batch size\n",
        "batch_size = 16  # Điều chỉnh dựa trên bộ nhớ GPU\n",
        "\n",
        "# Danh sách để lưu kết quả\n",
        "results = []\n",
        "\n",
        "# Xử lý câu theo batch\n",
        "for start_idx in range(0, len(sentences), batch_size):\n",
        "    batch_bus_names = bus_names[start_idx:start_idx + batch_size].tolist()\n",
        "    batch_sentences = sentences[start_idx:start_idx + batch_size].tolist()\n",
        "\n",
        "    # Encode sentences\n",
        "    inputs = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Dự đoán\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        scores = outputs.logits.softmax(dim=-1).cpu().numpy()\n",
        "\n",
        "    # Lưu kết quả vào danh sách\n",
        "    for i, (bus_name, sentence) in enumerate(zip(batch_bus_names, batch_sentences)):\n",
        "        results.append({\n",
        "            'Bus_Name': bus_name,\n",
        "            'Comment': sentence,\n",
        "            'POS': round(scores[i][model.config.label2id['POSITIVE']], 4),\n",
        "            'NEG': round(scores[i][model.config.label2id['NEGATIVE']], 4)\n",
        "            'NEU': round(scores[i][model.config.label2id['NEUTRAL']], 4)\n",
        "        })\n",
        "\n",
        "    # Giải phóng bộ nhớ GPU\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Chuyển danh sách kết quả thành DataFrame\n",
        "result_df = pd.DataFrame(results)\n",
        "\n",
        "# Lưu vào file CSV\n",
        "result_df.to_csv(\"sentiment_vi_results.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"Đã lưu kết quả vào sentiment_vi_results.csv\")"
      ],
      "metadata": {
        "id": "zt1CS2WMgmb_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}