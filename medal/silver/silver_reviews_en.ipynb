{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxfP8o9v6hMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d009d7a-9a00-42ea-d405-1b3353021f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=794e28e051414e678c36c5c8c5bdb8f6ebf27a280e948c36017dff044f6978bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from transformers import pipeline\n",
        "import json\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "from langdetect import detect, DetectorFactory\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfPFwvfq6hMd",
        "outputId": "be91ea60-36b6-4c93-fe25-24c51ab06256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Vietnamese comments: 6713\n",
            "Number of English comments: 611\n"
          ]
        }
      ],
      "source": [
        "# Set seed for reproducibility\n",
        "DetectorFactory.seed = 0\n",
        "\n",
        "# Load the JSON data\n",
        "with open('bus_reviews.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "df = df[['Bus Name', 'Comment']].rename(columns={'Bus Name': 'bus_name', 'Comment': 'comment'})\n",
        "\n",
        "# Function to detect language\n",
        "def detect_language(comment):\n",
        "    try:\n",
        "        return detect(comment)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Split data into English and Vietnamese comments\n",
        "df_vi = df[df['comment'].apply(lambda x: detect_language(x) == 'vi')].reset_index(drop=True)\n",
        "df_en = df[df['comment'].apply(lambda x: detect_language(x) == 'en')].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xTvt0wp6hMd",
        "outputId": "a4edaae6-e523-4663-bd8f-310e96a13f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã lưu kết quả vào sentiment_en_results.csv\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Giả sử 'bus_names' và 'sentences' là danh sách các tên nhà xe và bình luận\n",
        "bus_names = df_en['bus_name']\n",
        "sentences = df_en['comment']\n",
        "\n",
        "# Load tokenizer và model\n",
        "model_path = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Di chuyển model vào GPU nếu có\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Định nghĩa batch size\n",
        "batch_size = 16  # Điều chỉnh dựa trên bộ nhớ GPU\n",
        "\n",
        "# Danh sách để lưu kết quả\n",
        "results = []\n",
        "\n",
        "# Xử lý câu theo batch\n",
        "for start_idx in range(0, len(sentences), batch_size):\n",
        "    batch_bus_names = bus_names[start_idx:start_idx + batch_size].tolist()\n",
        "    batch_sentences = sentences[start_idx:start_idx + batch_size].tolist()\n",
        "\n",
        "    # Encode sentences\n",
        "    inputs = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Dự đoán\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        scores = outputs.logits.softmax(dim=-1).cpu().numpy()\n",
        "\n",
        "    # Lưu kết quả vào danh sách\n",
        "    for i, (bus_name, sentence) in enumerate(zip(batch_bus_names, batch_sentences)):\n",
        "        results.append({\n",
        "            'Bus_Name': bus_name,\n",
        "            'Comment': sentence,\n",
        "            'POS': round(scores[i][model.config.label2id['POSITIVE']], 4),\n",
        "            'NEG': round(scores[i][model.config.label2id['NEGATIVE']], 4)\n",
        "            # 'NEU': round(scores[i][model.config.label2id['NEUTRAL']], 4)\n",
        "        })\n",
        "\n",
        "    # Giải phóng bộ nhớ GPU\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Chuyển danh sách kết quả thành DataFrame\n",
        "result_df = pd.DataFrame(results)\n",
        "\n",
        "# Lưu vào file CSV\n",
        "result_df.to_csv(\"sentiment_en_results.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"Đã lưu kết quả vào sentiment_en_results.csv\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}